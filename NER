#This file shows the process of the exported articles from ProQuest into a list of European listed firms

#Load the packages
import spacy
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

#Load the data (key information about the articles)

# Read in the first CSV file (2016-2019 data)
df1 = pd.read_csv('20162019chatbot_2.csv', delimiter=';')

# Read in the second CSV file (2020-2023 data)
df2 = pd.read_csv('20202023chatbot_2.csv', delimiter=';')

# Concatenate the three dataframes together vertically
df = pd.concat([df1, df2])

#Descriptive statistic: Distribution articles over years
year = df['PubDate']
year = pd.to_datetime(year).dt.year
year_counts = year.value_counts()
plt.pie(year_counts, labels = year_counts.index, autopct = '%1.1f%%')
plt.axis('equal')
plt.savefig('piechart.png')
plt.show()


#Perform the NER
nlp = spacy.load("en_core_web_sm")

def extract_entities_with_date(row):
    title = str(row['Title'])
    subtitle = str(row['Subtitle'])
    abstract = str(row['Abstract'])
    text = title + ' ' + subtitle + ' ' + abstract
    doc = nlp(text)
    org_entities = []
    for ent in doc.ents:
        if ent.label_ == 'ORG':
            org_entities.append((ent.text, row['PubDate']))
    return org_entities

# Apply the updated function to the relevant columns of the dataframe and create a new column with the entities and dates
df['entities_with_date'] = df[['Title', 'Subtitle', 'Abstract', 'PubDate']].apply(extract_entities_with_date, axis=1)

#Count the number of unique entities
all_entities = list(set(df['entities_with_date'].sum()))
len(all_entities)

#Then, when the entities are created, it is time to load all stocks on the selected European stock indices.
#These are Excel files obtained from TopForeign Stocks.

#FTSE
ftse = pd.read_excel('FTSE100.xlsx')
ftse_list = ftse.iloc[:, 1].tolist()

#DAX
dax = pd.read_excel('dax40.xlsx')
dax_list = dax.iloc[:, 1].tolist()
ftse_list.extend(dax_list)

#CAC
cac = pd.read_excel('CAC40.xlsx')
cac_list = cac.iloc[:, 1].tolist()
ftse_list.extend(cac_list)

#IBEX
ibex = pd.read_excel('IBEX35.xlsx')
ibex_list = ibex.iloc[:, 1].tolist()
ftse_list.extend(ibex_list)

#MIB
mib = pd.read_excel('MIB40.xlsx')
mib_list = mib.iloc[:, 1].tolist()
ftse_list.extend(mib_list)

#AEX
aex = pd.read_excel('AEX.xlsx')
aex_list = aex.iloc[:, 1].tolist()
ftse_list.extend(aex_list) 

#BEL
bel = pd.read_excel('BEL20.xlsx')
bel_list = bel.iloc[:, 1].tolist()
ftse_list.extend(bel_list) 

#PSI
psi = pd.read_excel('PSI20.xlsx')
psi_list = psi.iloc[:, 1].tolist()
ftse_list.extend(psi_list) 

#SMI
smi = pd.read_excel('SMI.xlsx')
smi_list = smi.iloc[:, 1].tolist()
#Data cleaning step
smi_list = [company.replace('\xa0', '') for company in smi_list]
ftse_list.extend(smi_list) 

#ATX
atx = pd.read_excel('ATX.xlsx')
atx_list = atx.iloc[:, 1].tolist()
ftse_list.extend(atx_list) 

#OMX HELSINKI
omx_fin = pd.read_excel('OMX_FIN.xlsx')
omx_fin_list = omx_fin.iloc[:, 1].tolist()
ftse_list.extend(omx_fin_list) 

#OMX COPENHAGEN
omx_den = pd.read_excel('OMXDEN.xlsx')
omx_den_list = omx_den.iloc[:, 1].tolist()
ftse_list.extend(omx_den_list) 

#OBX
obx = pd.read_excel('OBX.xlsx')
obx_list = obx.iloc[:, 1].tolist()
ftse_list.extend(obx_list) 

#OMX STOCKHOLM
omx_swe = pd.read_excel('OMXSWE.xlsx')
omx_swe_list = omx_swe.iloc[:, 1].tolist()
ftse_list.extend(omx_swe_list) 

#WIG
wig = pd.read_excel('WIG.xlsx')
wig_list = wig.iloc[:20, 1].tolist()
ftse_list.extend(wig_list) 

#BUX
bux = pd.read_excel('BUX.xlsx')
bux_list = bux.iloc[:20, 1].tolist()
ftse_list.extend(bux_list) 

#Create the European stock list
european_stocks = set(ftse_list)

#Define the relevant legal terms for European companies
legal_terms = ['Inc.', 'Plc', 'Ltd.', 'N.V.', 'AG', 'SA', 'SE', 'S.A.', 'S.P.A.', 'Societas Europaea', 'GmbH', 'S.L.', 'A/S', 'OYJ', 'Spółka Akcyjna', 'B.V.', 'Kft.', 'd.o.o.']
# Remove legal terms from european_stocks
european_stocks = set([re.sub(rf"\b{term}\b", '', company).strip() for company in european_stocks for term in legal_terms])

#Perform the substring matching:
def search_companies_in_entities(all_entities, european_stocks):
    found_companies = []
    
    for company in european_stocks:
        for entity, date in all_entities:
            if company.lower() in entity.lower():
                found_companies.append((company, date))
                break
    
    return found_companies

found_companies = search_companies_in_entities(all_entities, european_stocks)

#Edit the date format
found_companies = found_companies[1:]
found_companies_to_excel = [(company, datetime.datetime.strptime(date, '%Y-%m-%d').strftime('%d/%m/%Y')) for company, date in found_companies]

#Export the file to Excel
found_companies_to_excel = pd.DataFrame(found_companies_to_excel, columns=['Company', 'Event date'])
found_companies_to_excel.to_excel('outpu4.xlsx', index=False)









