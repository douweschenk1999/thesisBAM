#This file shows the process of the exported articles from ProQuest into a list of American listed firms

#Load the packages
import spacy
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

#Load the data (key information about the articles)

# Read in the first CSV file (2016-2019 data)
df1 = pd.read_csv('20162019chatbot_2.csv', delimiter=';')

# Read in the second CSV file (2020-2023 data)
df2 = pd.read_csv('20202023chatbot_2.csv', delimiter=';')

# Concatenate the three dataframes together vertically
df = pd.concat([df1, df2])


#Perform the NER
nlp = spacy.load("en_core_web_sm")

def extract_entities_with_date(row):
    title = str(row['Title'])
    subtitle = str(row['Subtitle'])
    abstract = str(row['Abstract'])
    text = title + ' ' + subtitle + ' ' + abstract
    doc = nlp(text)
    org_entities = []
    for ent in doc.ents:
        if ent.label_ == 'ORG':
            org_entities.append((ent.text, row['PubDate']))
    return org_entities

# Apply the updated function to the relevant columns of the dataframe and create a new column with the entities and dates
df['entities_with_date'] = df[['Title', 'Subtitle', 'Abstract', 'PubDate']].apply(extract_entities_with_date, axis=1)

#Count the number of unique entities
all_entities = list(set(df['entities_with_date'].sum()))
len(all_entities)

#Then, when the entities are created, it is time to load all stocks on the selected American stock indices.
#These are Excel files obtained from TopForeign Stocks.

#S&P500
sp500 = pd.read_excel('S&P500.xlsx')
sp500_list = sp500.iloc[:, 1].tolist()

#NASDAQ100
nasdaq = pd.read_excel('NASDAQ100.xlsx')
nasdaq_list = nasdaq.iloc[:,1].tolist()
sp500_list.extend(nasdaq_list)

#DJIA
djia = pd.read_excel('DowJonesIndustrialAverage.xlsx')
djia_list = djia.iloc[:,1].tolist()
sp500_list.extend(djia_list)

#Create the total list
american_stocks = set(sp500_list)

#Define the legal terms
legal_terms_us = [
    'LLC', 'Limited Liability Company',
    'Inc.', 'Incorporated',
    'Corp.', 'Corporation',
    'Ltd.', 'Limited',
    'LP', 'Limited Partnership',
    'LLP', 'Limited Liability Partnership',
    'L.P.', 'Limited Partnership',
    'P.C.', 'Professional Corporation',
    'P.L.L.C.', 'Professional Limited Liability Company',
    'P.A.', 'Professional Association',
    'P.S.C.', 'Professional Service Corporation',
    'P.L.C.', 'Professional Limited Company',
    'Sole Proprietorship',
    'General Partnership',
    'L.L.P.', 'Limited Liability Partnership',
    'L.L.C.', 'Limited Liability Company'
]

#Data cleaning

# Remove legal terms from european_stocks
american_stocks = set([re.sub(rf"\b{term}\b", '', company).strip() for company in american_stocks for term in legal_terms_us])

#Substring matching
def search_companies_in_entities(all_entities, american_stocks):
    found_companies = []
    
    for company in american_stocks:
        for entity, date in all_entities:
            if company.lower() in entity.lower():
                found_companies.append((company, date))
                break
    
    return found_companies

found_companies = search_companies_in_entities(all_entities, american_stocks)

#Edit the date format
found_companies_to_excel = [(company, datetime.datetime.strptime(date, '%Y-%m-%d').strftime('%d/%m/%Y')) for company, date in found_companies]

#Export the file to Excel
found_companies_to_excel = pd.DataFrame(found_companies_to_excel, columns=['security_ticker', 'event_date'])

found_companies_to_excel.to_excel('output_us.xlsx', index=False)


